{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO88rkndlLs6v72ch6NO9k6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AtbBP9FO9fHh"},"outputs":[],"source":["!unzip -q rice-dataset-sample.zip"]},{"cell_type":"code","source":["!pip install split-folders"],"metadata":{"id":"m80uyXDB9xbd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(f\"Dispositivo disponible: {device}\")"],"metadata":{"id":"sC8K-4qc9xtq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## División de los conjuntos train, val y test\n"],"metadata":{"id":"bKH4q1PW92Br"}},{"cell_type":"code","source":["import splitfolders\n","\n","input_dir = '/content/rice-dataset-sample'\n","output_dir = '/content/rice-dataset-sample-splits'\n","\n","splitfolders.ratio(\n","    input_dir,\n","    output=output_dir,\n","    seed=42,\n","    ratio=(.7, .2, .1)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q35pV_pq9y9z","executionInfo":{"status":"ok","timestamp":1710755398431,"user_tz":-60,"elapsed":213,"user":{"displayName":"Pablo Guti Ruiz","userId":"07443762493544230230"}},"outputId":"cac3f6b1-ba67-4217-d171-cd61783c15d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Copying files: 50 files [00:00, 5164.00 files/s]\n"]}]},{"cell_type":"markdown","source":["## Instanciar DataLoaders"],"metadata":{"id":"_0hNUm_i934q"}},{"cell_type":"code","source":["from torchvision import transforms\n","\n","transform = transforms.Compose([\n","    transforms.Resize((28, 28)),\n","    transforms.ToTensor(),\n","])"],"metadata":{"id":"Pwpx9PHv96h5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import datasets\n","\n","dataset_path = '/content/rice-dataset-sample-splits'\n","\n","train_dataset = datasets.ImageFolder(root=f\"{dataset_path}/train\", transform=transform)\n","val_dataset = datasets.ImageFolder(root=f\"{dataset_path}/val\", transform=transform)\n","test_dataset = datasets.ImageFolder(root=f\"{dataset_path}/test\", transform=transform)"],"metadata":{"id":"SimO64Ix98Tl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","batch_size = 16\n","shuffle = True\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)"],"metadata":{"id":"uVVK-TwO99Jt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Primera red convolucional"],"metadata":{"id":"hCf1Xa2yDKfT"}},{"cell_type":"code","source":[" import torch.nn as nn\n"," import torch.nn.functional as F\n","\n"," class SimpleConvNet(nn.Module):\n","  def __init__(self):\n","    super(SimpleConvNet, self).__init__()\n","    # TODO: Crea una capa convolucional de 2 dimensiones con los parámetros:\n","    # - in_channels = 3\n","    # - out_channels = 16\n","    # - kernel_size = 3\n","    # - padding = 1\n","    # TIP: Consulta la documentación de la función Conv2d\n","    self.conv = nn.Conv2d(\n","        in_channels=3,\n","        out_channels=16,\n","        kernel_size=3,\n","        padding=1\n","    )\n","    # TODO: Crea una capa de maxpool de 2 dimensiones con los parámetros:\n","    # - kernel_size = 2\n","    # - stride = 2\n","    # TIP: Consulta la documentación de la función MaxPool2d\n","    self.pool = nn.MaxPool2d(\n","        kernel_size=2,\n","        stride=2\n","    )\n","    self.fc1 = nn.Linear(16 * 14 * 14, 120)\n","    self.fc2 = nn.Linear(120, 5)\n","\n","  def forward(self, x):\n","    output = self.conv(x)\n","    output = F.relu(output)\n","    output = self.pool(output)\n","    output = torch.flatten(output, 1)\n","    output = self.fc1(output)\n","    output = F.relu(output)\n","    output = self.fc2(output)\n","\n","    return output"],"metadata":{"id":"cPO3azxC-AN3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = SimpleConvNet().to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZRalDd1EuK1","executionInfo":{"status":"ok","timestamp":1710758306035,"user_tz":-60,"elapsed":6,"user":{"displayName":"Pablo Guti Ruiz","userId":"07443762493544230230"}},"outputId":"bc1c2238-2409-42a0-fa4a-23959ec0c093"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SimpleConvNet(\n","  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=3136, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=5, bias=True)\n",")"]},"metadata":{},"execution_count":75}]},{"cell_type":"markdown","source":["## Entrenar la red convolucional"],"metadata":{"id":"8SwLRcTkFq5-"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())"],"metadata":{"id":"Rg5t3u68FFCr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 5\n","\n","for epoch in range(num_epochs):\n","  running_loss = 0.0\n","  for inputs, labels in train_dataloader:\n","    # TODO: Envía los inputs y las labels al device adecuado\n","    inputs, labels = inputs.to(device), labels.to(device)\n","\n","    # TODO: Deja a cero los gradientes del opitmizador\n","    # TIPO: Consulta la función zero_grad\n","    optimizer.zero_grad()\n","\n","    # TODO: Calcula el output del modelo\n","    outputs = model(inputs)\n","\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","\n","  print(f\"Epoch: {epoch+1} Loss: {running_loss/len(train_dataloader)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImK_fs76FxoU","executionInfo":{"status":"ok","timestamp":1710758306695,"user_tz":-60,"elapsed":244,"user":{"displayName":"Pablo Guti Ruiz","userId":"07443762493544230230"}},"outputId":"03ad4b20-e775-48d6-aabe-d0d01f0f392c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1 Loss: 1.6498209238052368\n","Epoch: 2 Loss: 1.583358883857727\n","Epoch: 3 Loss: 1.496825893719991\n","Epoch: 4 Loss: 1.4010985294977825\n","Epoch: 5 Loss: 1.3505812486012776\n"]}]},{"cell_type":"markdown","source":["## Evaluar la red convolucional"],"metadata":{"id":"uoaQRPjnJMod"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","model.eval()\n","\n","with torch.no_grad():\n","  all_preds = []\n","  all_labels = []\n","\n","  for inputs, labels in test_dataloader:\n","    inputs, lagbels = inputs.to(device), labels.to(device)\n","\n","    # TODO: Calcula la salida del modelo\n","    outputs = model(inputs)\n","\n","    _, preds = torch.max(outputs, 1)\n","\n","    all_preds.extend(preds.numpy(force=True))\n","    all_labels.extend(labels.numpy(force=True))\n","\n","print(classification_report(all_labels, all_preds, target_names=test_dataset.classes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vc-1j7oMGmOw","executionInfo":{"status":"ok","timestamp":1710758552486,"user_tz":-60,"elapsed":1109,"user":{"displayName":"Pablo Guti Ruiz","userId":"07443762493544230230"}},"outputId":"6b45535b-66a5-48af-b3de-d425a7520996"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","     Arborio       0.50      1.00      0.67         1\n","     Basmati       0.00      0.00      0.00         1\n","      Ipsala       0.50      1.00      0.67         1\n","     Jasmine       0.00      0.00      0.00         1\n","   Karacadag       0.00      0.00      0.00         1\n","\n","    accuracy                           0.40         5\n","   macro avg       0.20      0.40      0.27         5\n","weighted avg       0.20      0.40      0.27         5\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]}]}